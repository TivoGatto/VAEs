{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beta_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmh3qIsDYRpfUTe22TDHhH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TivoGatto/VAEs/blob/master/beta_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE7BpF2_C5EP",
        "colab_type": "code",
        "outputId": "2934d0e2-8c0e-4831-9c8c-0584438f28e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# LIBRARIES\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Lambda, Reshape, BatchNormalization, ReLU, Flatten\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0t5oWOLDA2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "input_dim = (32, 32, 1)\n",
        "intermediate_dim = 256\n",
        "latent_dim = 4\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 20\n",
        "epsilon_std = 1.0\n",
        "\n",
        "beta = 3\n",
        "C = 3\n",
        "\n",
        "# SAVING OPTIONS\n",
        "SAVE_MODEL = True\n",
        "PRINT_MODEL = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-Ap_0xZDJIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions\n",
        "\n",
        "def vae_loss(x_true, x_pred):\n",
        "\tx_true = K.reshape(x_true, (-1, np.prod(input_dim)))\n",
        "\tx_pred = K.reshape(x_pred, (-1, np.prod(input_dim)))\n",
        "\n",
        "\txent_loss = K.mean(0.5 * K.sum(K.square(x_true - x_pred), axis=-1))\n",
        "\treg_loss = K.mean(0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - 1 - z_log_var, axis=-1))\n",
        "\n",
        "\treturn K.mean(xent_loss + beta * K.abs(reg_loss - C))\n",
        " \n",
        "def reconstruction(x_true, x_pred):\n",
        "\tx_true = K.reshape(x_true, (-1, np.prod(input_dim)))\n",
        "\tx_pred = K.reshape(x_pred, (-1, np.prod(input_dim)))\n",
        "\n",
        "\treturn K.mean(0.5 * K.sum(K.square(x_true - x_pred), axis=-1))\n",
        "\n",
        "def regularizer(x_true, x_pred):\n",
        "    reg_loss = K.mean(0.5 * K.sum(K.square(z_mean) + K.exp(z_log_var) - 1 - z_log_var, axis=-1))\n",
        "\n",
        "    return K.mean(reg_loss)\n",
        "\n",
        "def sampling(args):\n",
        "\tz_mean, z_log_var = args\n",
        "\tepsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0, stddev=epsilon_std)\n",
        "\n",
        "\treturn z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "def pad(x, n):\n",
        "\td = x.shape[1]\n",
        "\tN = len(x)\n",
        "\n",
        "\tdata = np.zeros(shape=(N, n, n))\n",
        "\tfor i in range(N):\n",
        "\t\tdata[i, :d, :d] = x[i]\n",
        "\t\n",
        "\treturn data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PANMS5bDWQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model\n",
        "# ENCODER\n",
        "x = Input(shape=(input_dim))\n",
        "\n",
        "h = Conv2D(32, 4, strides=(2, 2), padding='same')(x)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2D(64, 4, strides=(2, 2), padding='same')(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2D(128, 4, strides=(2, 2), padding='same')(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "shape_before_flattening = K.int_shape(h)\n",
        "h = Flatten()(h)\n",
        "\n",
        "h = Dense(intermediate_dim, activation='relu')(h)\n",
        "\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "z = Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(x, [z, z_mean, z_log_var])\n",
        "\n",
        "# DECODER\n",
        "z_in = Input(shape=(latent_dim, ))\n",
        "\n",
        "h = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(z_in)\n",
        "\n",
        "h = Reshape(shape_before_flattening[1:])(h)\n",
        "\n",
        "h = Conv2DTranspose(128, 4, strides=(2, 2), padding='same')(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2DTranspose(64, 4, strides=(2, 2), padding='same')(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "h = Conv2DTranspose(32, 4, strides=(2, 2), padding='same')(h)\n",
        "h = BatchNormalization()(h)\n",
        "h = ReLU()(h)\n",
        "\n",
        "x_recon = Conv2DTranspose(1, 4, strides=(1, 1), padding='same', activation='sigmoid')(h)\n",
        "\n",
        "decoder = Model(z_in, x_recon)\n",
        "\n",
        "# VAE\n",
        "x_pred = decoder(z)\n",
        "vae = Model(x, x_pred)\n",
        "\n",
        "optimizer = Adam(lr=5e-4)\n",
        "vae.compile(optimizer=optimizer, loss=vae_loss, metrics=[reconstruction, regularizer])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8-vfHPCDfy8",
        "colab_type": "code",
        "outputId": "a7ed200a-5fa4-4cd8-e78c-9894b91757ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "\n",
        "x_train = pad(x_train, 32)\n",
        "x_test = pad(x_test, 32)\n",
        "\n",
        "x_train = np.reshape(x_train, (-1, ) + input_dim)\n",
        "x_test = np.reshape(x_test, (-1, ) + input_dim)\n",
        "\n",
        "print(\"X_train shape: \", x_train.shape)\n",
        "print(\"X_test shape: \", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (60000, 32, 32, 1)\n",
            "X_test shape:  (10000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QPa74QhDqDN",
        "colab_type": "code",
        "outputId": "2d37a2b5-f84f-4945-df21-e69da3297345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "# TRAIN\n",
        "hist = vae.fit(x_train, x_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "if SAVE_MODEL:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    vae.save('beta_vae.h5', overwrite=True)\n",
        "    encoder.save('beta_vae_encoder.h5', overwrite=True)\n",
        "    decoder.save('beta_vae_decoder.h5', overwrite=True)\n",
        "\n",
        "if PRINT_MODEL:\n",
        "    from keras.utils import plot_model\n",
        "\n",
        "    plot_model(vae, 'beta_vae.png', show_shapes=True)\n",
        "    plot_model(encoder, 'beta_vae_encoder.png', show_shapes=True)\n",
        "    plot_model(decoder, 'beta_vae_decoder.png', show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 4800/60000 [=>............................] - ETA: 7:56 - loss: 110.6136 - reconstruction: 75.6019 - regularizer: 14.4786"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-032da1e122e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSAVE_MODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyKQYy90dKcJ",
        "colab_type": "text"
      },
      "source": [
        "Ho trainato per 20 epochs, e noto che inizialmente scende il reconstruction error, e il regularizer rimane praticamente fermo (attorno a 4 come valore). Dopo un po' di epoche, inizia a scendere velocemente verso zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fudqVnUHZJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_values = encoder.predict(x_train, batch_size=batch_size)[0]\n",
        "z_values = np.array(z_values)\n",
        "\n",
        "plt.scatter(z_values[:, 0], z_values[:, 1], c=y_train)\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"z_0\")\n",
        "plt.ylabel(\"z_1\")\n",
        "plt.title(\"Latent Space Visualization MNIST\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBP_zP2PQkZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_recon = vae.predict(x_train, batch_size=batch_size)\n",
        "\n",
        "x_train_temp = np.reshape(x_train, (-1, 32, 32))\n",
        "x_recon_temp = np.reshape(x_recon, (-1, 32, 32))\n",
        "\n",
        "n = 10\n",
        "fig_size = 32\n",
        "for i in range(n):\n",
        "    figure = np.zeros(shape=(fig_size, fig_size * 2))\n",
        "\n",
        "    figure[:, :fig_size] = x_train_temp[i]\n",
        "    figure[:, fig_size:] = x_recon_temp[i]\n",
        "\n",
        "    plt.imshow(figure, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bp49zVLV9Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating samples from p(z) = N(O, I)\n",
        "n = 10\n",
        "digit_size = 32\n",
        "stddev = 2\n",
        "\n",
        "z_values = np.random.normal(size=(n ** 2, latent_dim), scale=stddev)\n",
        "x_generated = decoder.predict(z_values, batch_size=n ** 2)\n",
        "\n",
        "x_generated_temp = np.reshape(x_generated, (n ** 2, 32, 32))\n",
        "figure = np.zeros(shape=(n * digit_size, n * digit_size))\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        figure[j * digit_size : (j+1) * digit_size, i * digit_size : (i+1) * digit_size] = x_generated_temp[i + j * n]\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}